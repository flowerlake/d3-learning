<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!--<meta name="viewport" content="width=device-force_width,initial-scale=1">-->
    <!--<meta property="og:description"-->
    <!--content="How the Final Presidential Debate Played on the Subconscious Minds of Voters">-->
    <!--<meta property="og:image" content="/debate/debate.png">-->
    <!--<meta property="og:site_name" content="Brainsights">-->
    <!--<meta property="og:title" content="THE POLITICAL BRAIN">-->
    <!--<meta property="og:type" content="article">-->
    <!--<meta property="og:url" content="http://politics.andyourbrain.com/debate">-->
    <!--<meta name="twitter:card" content="summary_large_image">-->
    <!--<meta name="twitter:url" content="http://politics.andyourbrain.com/debate">-->
    <!--<meta name="twitter:title" content="THE POLITICAL BRAIN">-->
    <!--<meta name="twitter:description"-->
    <!--content="How the Final Presidential Debate Played on the Subconscious Minds of Voters">-->
    <!--<meta name="twitter:image:src" content="/debate/debate.gif">-->
    <!--<meta name="twitter:site" content="Brainsights">-->
    <title>THE POLITICAL BRAIN: How the Final Presidential Debate Played on the Subconscious Minds of Voters</title>
    <link href="css/css.css" rel="stylesheet">
    <link href="css/main.css" rel="stylesheet">
</head>

<body>
    <div id="root">
        <div data-reactroot="" class="App" style="width: 1000px; margin: auto;">
            <div style="text-align: center;">
                <img src="image/transparent.png" width="452"><br>
                <br><br><br>
                <h1>The Political Brain</h1>
                <h3>
                    <!-- react-text: 11 -->How the Final Presidential Debate
                    <!-- /react-text --><br><!-- react-text: 13 -->
                    Played on the Subconscious Minds of Voters
                    <!-- /react-text -->
                </h3>
            </div>
            <div style="position: relative;">
                <svg width="1000" height="820"></svg>
                <div></div>
            </div>
            <div style="padding: 0px 20px; font-size: 14px; line-height: 1.6;">
                <h2>Why We Made this Tool</h2>
                <p>Polls now show <span style="color: #51aae8"><strong>Hillary Clinton</strong></span> with a
                    commanding
                    lead, but voters should approach these numbers with caution. It's been a campaign soaked in emotion
                    and
                    irrationality – misogyny, scandal, racism, xenophobia, arson, misinformation, and violence. Under
                    these
                    conditions, it’s hazardous to fully trust the stated response methodology of political polling to
                    get a
                    read on voter intention. What we say we’ll do, and what we actually do, are often very different.</p>
                <p>So, to peel back this conscious layer and reveal the subconscious workings of voters and citizens,
                    <strong>Brainsights</strong> deployed its audience brain measurement platform to measure the
                    subconscious brain activity of 60 citizens as they watched the final Presidential debate live.</p>
                <p>Using electroencephalography (EEG) – devices that use small electrodes to measure brain waves –
                    <strong>Brainsights</strong>
                    is able to pick up on the tiny signals in the brain that fire off every millisecond without our
                    knowing,
                    and which drive our decision-making. Specifically, <strong>Brainsights</strong>’ technology
                    measures
                    audience <strong>Attention</strong>, emotional <strong>Connection</strong> and <strong>Encoding</strong>
                    to memory – quite literally, what we attune to, what we identify or bond with, and what we find
                    value
                    enough to store away in our memory. Together, these measures combine for a read on the engagement
                    or
                    persuasiveness of specific stimuli.</p>
                <p>The technology platform syncs this brain data at the millisecond level to the visual stimuli each
                    viewer
                    is processing – in this instance, the third and final Presidential debate. The
                    <strong>Brainsights</strong> team coded every second of the debate, tagging each moment with which
                    candidate was on screen, who was speaking, and about what topics. Where there was a ‘zinger’ or a
                    candidate attack, we coded those, too.</p>
                <p>All of this was linked to the profile data of participants. We’ve broken this down into <span style="color: #1cc6aa"><strong>six
                            groups</strong></span> you can compare – Males and Females, for
                    which there were equal numbers; under and over 30 years old (another 50/50 split) and Americans and
                    non-Americans, where there were 20 of the former, and 40 of the latter (the event happened in
                    Toronto).
                    But while these numbers may seem small, for neuroscience-based studies, they’re actually huge – by
                    comparison, most PhD theses using EEG have 15-20 participant samples.</p>
                <h2>How to read this visualization</h2>
                <p>The time series charts have two default lines. The horizontal line is the average score for everyone
                    across the entire debate. The single line is a combined score – moment-to-moment - of audience
                    <strong>Attention</strong>,
                    <strong>Connection</strong> and <strong>Encoding</strong>, which ebbs and flows in response to the
                    stimuli on screen. Where this rises above the average, it means the audience is engaged or
                    persuaded by
                    what they’re seeing and hearing. Where you see it dip below, it’s the opposite – voters don’t care
                    much
                    about what the candidate is saying. You can select specific <span style="color: #1cc6aa"><strong>demographic
                            groups</strong></span>
                    to map against these average scores*.</p>
                <p>Select specific moments to dive into more detail further below, including how the audience responds
                    to
                    specific quotes from the candidates, or as they discuss different topics. Colour shading in the
                    chart
                    refers to who’s speaking – <span style="color: #51aae8"><strong>Blue is Hillary</strong></span>;
                    <span style="color: #e75d87"><strong>Red is Trump</strong></span>; <span style="color: #f7d283"><strong>Yellow
                            is the moderator Chris Wallace</strong></span>. And where
                    you see White, that’s where the candidates and the moderator are speaking over one another and it
                    was
                    difficult for us to determine who was saying what**.</p>
                <p>Finally, if you have any ideas as to how we can make this a better tool, tell us. Let us know if
                    we’ve
                    missed anything or any moments of interest. We’re eager to make this as useful a tool as possible
                    for
                    you, so you can better understand how the subconscious mind responds to political communications –
                    what’s persuasive, what’s engaging – and thus make a more informed decision come Election Day.</p>
                <p><sub>
                        *Note: Positive/Negative valence is not intrinsic to this data. In other words, because a
                        response is
                        above or below mean doesn't mean that it's liked/disliked. However, the interaction between
                        <strong>Attention</strong>,
                        <strong>Connection</strong> and <strong>Encoding</strong> metrics - which can be found in the
                        details -
                        can help to tease this out: Where <strong>Connection</strong> rises and <strong>Attention</strong>
                        drops, people are withdrawing from the stimuli on screen, and considering the implications of
                        what's
                        been said/shown. In the past, this has indicated confusion, disdain, and other negative
                        emotions. For an
                        example of this phenomena, look at the details for Trump's "Nobody has more respect for women"
                        claim for
                        females. Connection rises more than Attention, and stays higher than Attention even as overall
                        engagement drops.
                    </sub></p>
                <p><sub>
                        **You'll see we pulled the official transcript from the closed captioning of the debate. We
                        wanted to
                        give you full context of what was happening. However, as with closed captioning, the syncing of
                        the text
                        to what was said can be off by 1 or 2 seconds. Also - here's a <a href="https://www.youtube.com/watch?v=smkyorC5qwc"
                            target="_new">link</a> to the debate file we
                        screened.
                    </sub></p>
            </div>

        </div>
        <script type="text/javascript" src="js/main.js"></script>
        <!--<div id="Vidown_extension_alhnopeoagjmjfgcbnokcnagkecgdcdh" style="display: none;"></div>-->
    </div>
</body>

</html>